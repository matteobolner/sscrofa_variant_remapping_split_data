Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	split_file
	1

[Tue Nov 10 22:38:27 2020]
rule split_file:
    input: data/starting_file.txt
    output: data/gene_dirs/test.txt
    jobid: 0

[Tue Nov 10 22:38:27 2020]
Error in rule split_file:
    jobid: 0
    output: data/gene_dirs/test.txt
    shell:
        mkdir gene_dirs | cd gene_dirs | awk -F '|' '{print >  $2}' data/starting_file.txt
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/pelmo/tesi/remap_sscrofa/.snakemake/log/2020-11-10T223827.376845.snakemake.log
